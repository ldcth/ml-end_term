{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'gpu'\n",
    "import copy\n",
    "\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = \"./data/book-full-listing-train.csv\"\n",
    "TEST_CSV = \"./data/book-full-listing-test.csv\"\n",
    "df = pd.read_csv(TRAIN_CSV)\n",
    "df_test = pd.read_csv(TEST_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Amazon ID (ASIN)','Filename','Image URL'],axis=1,inplace=True)\n",
    "df_test.drop(['Amazon ID (ASIN)','Filename','Image URL'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    review = raw_review\n",
    "    review = re.sub('[^a-zA-Z]', ' ',review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    review = [lemmatizer.lemmatize(w) for w in review if w not in set(stopwords.words('english'))]\n",
    "    res = (' '.join(review))\n",
    "    if res == '' or res == ' ':\n",
    "        return raw_review\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus= []\n",
    "for i in range(0, len(df.index)):\n",
    "    corpus.append(review_to_words(df['Title'][i]))\n",
    "corpus_test= []\n",
    "for i in range(0, len(df_test.index)):\n",
    "    corpus_test.append(review_to_words(df_test['Title'][i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['corpus']=corpus\n",
    "df_test['corpus']=corpus_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6577 entries, 0 to 6576\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Amazon ID (ASIN)  6577 non-null   object\n",
      " 1   Filename          6577 non-null   object\n",
      " 2   Image URL         6577 non-null   object\n",
      " 3   Title             6577 non-null   object\n",
      " 4   Author            6194 non-null   object\n",
      " 5   Category ID       6577 non-null   int64 \n",
      " 6   Category          6577 non-null   object\n",
      " 7   label             6577 non-null   int64 \n",
      " 8   resnet34mini      6577 non-null   object\n",
      " 9   corpus            6577 non-null   object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 514.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(TRAIN_CSV, index=False)\n",
    "df_test.to_csv(TEST_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_CV_JOBLIB_PATH = './joblib/big/cv.joblib'\n",
    "BIG_NB_JOBLIB_PATH = './joblib/big/nb.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_classifier = joblib.load(BIG_NB_JOBLIB_PATH)\n",
    "cv = joblib.load(BIG_CV_JOBLIB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = cv.transform(df['corpus']).toarray()\n",
    "x_test = cv.transform(df_test['corpus']).toarray()\n",
    "y_train = df['Category'].values\n",
    "y_test = df_test['Category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = loaded_classifier.predict_proba(x_train)\n",
    "y_pred_test = loaded_classifier.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8020374030713091\n"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nb_cv_20000']=y_pred_train.tolist()\n",
    "df_test['nb_cv_20000']=y_pred_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "def get_net():\n",
    "    resnet = torchvision.models.resnet34(pretrained=True)\n",
    "\n",
    "    # Substitute the FC output layer\n",
    "    resnet.fc = torch.nn.Linear(resnet.fc.in_features, 10)\n",
    "    torch.nn.init.xavier_uniform_(resnet.fc.weight)\n",
    "    return resnet\n",
    "\n",
    "class ModelSoftmax(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        y = self.softmax(x)\n",
    "        return y\n",
    "\n",
    "class ResnetVote:\n",
    "    def __init__(self, model: nn.Module):\n",
    "        self.model=model.to('cuda').eval()\n",
    "    \n",
    "    def __call__(self, x: torch.Tensor) -> Any:\n",
    "        return self.model(x.to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('./ckpt/resnet34mini.pth.tar')\n",
    "net = get_net()\n",
    "net.load_state_dict(checkpoint['state_dict'])\n",
    "modelsoftmax = ModelSoftmax(net)\n",
    "resnetvote = ResnetVote(modelsoftmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
